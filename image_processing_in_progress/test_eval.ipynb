{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10abcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#import numpy as np\n",
    "import os\n",
    "from modules_segmentation import *\n",
    "from mask_corners import gridcorners\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a46ea501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set paths\n",
    "image_folder = \"/user/christoph.wald/u15287/big-scratch/02_splitted_data/train_labeled/images_uncropped\"\n",
    "image_files = os.listdir(image_folder)\n",
    "pest_types = [\"BRAIIM\", \"LIRIBO\", \"TRIAVA\"]\n",
    "test_folder = \"/user/christoph.wald/u15287/insect_pest_detection/image_processing_in_progress/test_segmentation\"\n",
    "\n",
    "#load mask\n",
    "grown_mask = cv2.imread(\n",
    "    \"/user/christoph.wald/u15287/insect_pest_detection/2_4_image_processing/mask.jpg\", \n",
    "    cv2.IMREAD_GRAYSCALE\n",
    ")\n",
    "\n",
    "inspection = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2817ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f6cfeaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LIRIBO_0629.jpg.\n",
      "26 bounding boxes found.\n",
      "16 bounding boxes found.\n",
      "Loading BRAIIM_0003.jpg.\n",
      "19 bounding boxes found.\n",
      "19 bounding boxes found.\n",
      "Loading LIRIBO_0002.jpg.\n",
      "23 bounding boxes found.\n",
      "10 bounding boxes found.\n",
      "Loading TRIAVA_0136.jpg.\n",
      "14 bounding boxes found.\n",
      "43 bounding boxes found.\n",
      "Loading BRAIIM_0945.jpg.\n",
      "18 bounding boxes found.\n",
      "18 bounding boxes found.\n",
      "   prefix    TP    FP    FN  precision    recall\n",
      "0  BRAIIM  2578  2867  1905   0.473462  0.575061\n",
      "1  LIRIBO  3338  4998  1594   0.400432  0.676805\n",
      "2  TRIAVA  1121  2198  6819   0.337752  0.141184\n",
      "Overall precision: 0.4115204678362573\n",
      "Overall recall: 0.4054739268222414\n"
     ]
    }
   ],
   "source": [
    "for image_file in image_files[:5]:\n",
    "\n",
    "    filename= image_file.split(\".\")[0]\n",
    "    entry = []\n",
    "    entry.append(filename)\n",
    "\n",
    "    #Load image file\n",
    "    print(f\"Loading {image_file}.\")\n",
    "    image = cv2.imread(os.path.join(image_folder, image_file))\n",
    "    if inspection: cv2.imwrite(os.path.join(test_folder, filename + \"_original.jpg\"), image)\n",
    "    \n",
    "    #find YST contour of image\n",
    "    imageYST = find_contour(image)\n",
    "    imagecorners = find_corners(image, imageYST)\n",
    "    if len(imagecorners) == 0:\n",
    "        print(f\"No YST found for {image_file}\")\n",
    "        continue\n",
    "    imagecorners = order_corners(imagecorners)\n",
    "\n",
    "    #find transformation and apply to mask\n",
    "    H, _ = cv2.findHomography(gridcorners, imagecorners, cv2.RANSAC)\n",
    "    mask = cv2.warpPerspective(grown_mask, H, (image.shape[1], image.shape[0]))\n",
    "    if inspection: cv2.imwrite(os.path.join(test_folder, filename + \"_aligned_mask.jpg\"), mask) \n",
    "    \n",
    "    '''\n",
    "    #second transformation to secure vertical alignment\n",
    "    mask_h = get_h_mid(mask)\n",
    "    image_h = get_h_mid(create_binary_mask(image))\n",
    "    dy = get_midpoint(image_h)- get_midpoint(mask_h)\n",
    "    if inspection:\n",
    "        check_h_line(mask, mask_h)\n",
    "        check_h_line(create_binary_mask(image), image_h)\n",
    "    H, W = mask.shape[:2]\n",
    "    M = np.float32([[1, 0, 0], [0, 1, dy]])  # translation matrix\n",
    "    shifted_mask= cv2.warpAffine(mask, M, (W, H), borderValue=255)  # white background\n",
    "    reset the following to shifted_mask\n",
    "    if inspection: cv2.imwrite(os.path.join(test_folder, filename + \"_shifted_mask.jpg\")) \n",
    "    '''\n",
    "\n",
    "    #replace black background in image with yellow (background color) by using the mask\n",
    "    yellow_mask = mask == 0\n",
    "    image_wo_grid = image.copy()\n",
    "    image_wo_grid[yellow_mask] = [0,255,255]\n",
    "    if inspection: cv2.imwrite(os.path.join(test_folder, filename + \"_wo_grid.jpg\"), image_wo_grid) \n",
    "    \n",
    "    #crop the image\n",
    "    x, y, w, h = cv2.boundingRect(imageYST)\n",
    "    cropped_image_wo_grid = image_wo_grid[y:y+h, x:x+w]\n",
    "    if inspection: cv2.imwrite(os.path.join(test_folder, filename + \"_cropped.jpg\"), cropped_image_wo_grid) \n",
    "    \n",
    "    #handcrafted features for filtering bounding boxes\n",
    "    if \"TRIAVA\" in image_file:\n",
    "        min_area = 100  \n",
    "        max_area = 1000 \n",
    "    else:\n",
    "        min_area = 1000 \n",
    "        max_area = 10000 \n",
    "\n",
    "    #find bounding boxes, filtered by handcrafted features and ratio of w/h, scale them    \n",
    "    if inspection: cv2.imwrite(os.path.join(test_folder, filename + \"_binary_mask.jpg\"), create_binary_mask(cropped_image_wo_grid)) \n",
    "    rectangles= get_list_of_rectangles(cropped_image_wo_grid, min_area, max_area, scale = 1.5, max_ratio = 2)\n",
    "\n",
    "    ##changed from here\n",
    "    #only for testing: draw the found boxes into the labeled image\n",
    "    image_cropped = image[y:y+h, x:x+w]\n",
    "    image_labels = draw_bounding_boxes(image_cropped, rectangles)\n",
    "    cv2.imwrite(os.path.join(test_folder, filename + \"_w_labels.jpg\"), image_labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #finding the rectangles given by the yolo labels\n",
    "    label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "    labels_path = \"/user/christoph.wald/u15287/big-scratch/02_splitted_data/train_labeled/labels_uncropped\"\n",
    "    label_path = os.path.join(labels_path, label_file)\n",
    "    with open(label_path, \"r\") as f:\n",
    "        yolo_labels = f.read().splitlines()\n",
    "    yolo_rectangles = yolo_labels_to_rectangles(yolo_labels, image.shape)\n",
    "    cropped_yolo_rectangles = transform_rectangles_to_cropped(yolo_rectangles, x, y,  w,h)\n",
    "    #image_labels = draw_bounding_boxes(image, yolo_rectangles, color = (0,255,0))\n",
    "    #cv2.imwrite(os.path.join(test_folder, filename + \"_w_labels.jpg\"), image_labels)\n",
    "    image_labels = draw_bounding_boxes(image_labels, cropped_yolo_rectangles, color = (0,255,0))\n",
    "    cv2.imwrite(os.path.join(test_folder, filename + \"_w_labels.jpg\"), image_labels)\n",
    "    rectangles = [(x, y, x + w, y + h) for (x, y, w, h) in rectangles]\n",
    "    cropped_yolo_rectangles = [(x, y, x + w, y + h) for (x, y, w, h) in cropped_yolo_rectangles]\n",
    "    entry.append(evaluate_detections(rectangles, cropped_yolo_rectangles))\n",
    "    results.append(entry)\n",
    "\n",
    "#evaluate\n",
    "rows = []\n",
    "for name, metrics in results:\n",
    "    row = {\"image\": name, **metrics}  # merge the dict with image name\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['prefix'] = df['image'].str[:6]  # first 6 chars like LIRIBO, BRAIIM, TRIAVA\n",
    "\n",
    "# Sum TP, FP, FN over each prefix\n",
    "grouped = df.groupby('prefix')[['TP', 'FP', 'FN']].sum().reset_index()\n",
    "grouped['precision'] = grouped['TP'] / (grouped['TP'] + grouped['FP'])\n",
    "grouped['recall'] = grouped['TP'] / (grouped['TP'] + grouped['FN'])\n",
    "\n",
    "TP_total = df['TP'].sum()\n",
    "FP_total = df['FP'].sum()\n",
    "FN_total = df['FN'].sum()\n",
    "\n",
    "precision_overall = TP_total / (TP_total + FP_total)\n",
    "recall_overall = TP_total / (TP_total + FN_total)\n",
    "\n",
    "print(grouped)\n",
    "print(\"Overall precision:\", precision_overall)\n",
    "print(\"Overall recall:\", recall_overall)\n",
    "grouped.to_csv(\"results_image_processing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9869f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
